\section{Requirements}\label{Reqs}

\subsection{High Level Requirements}\label{ReqsHiLev}

\begin{tabular}{|p{4cm}|p{12cm}|}\hline
  \textbf{Scalable} & Resource Manager will scale up to 100,000 compute
	nodes per cluster and will scale to many clusters to allow
	management of even the largest centers \\
  \hline
  \textbf{Reliable} & Resource Manager will not have a single point of
	failure and shall never require scheduled downtime for software
	upgrades. Fault tolerance will be incorporated at every level. \\
  \hline
  \textbf{Secure} & Resource Manager will support wire protocols with
	built-in privacy and data integrity. \\
  \hline
  \textbf{Extensible} & Resource Manager will support plugins with clean
	interfaces wherever possible to facilitate collaboration,
	customization, and novel functionality. \\
  \hline
  \textbf{Research Friendly} & Resource Manager design will incorporate
	features that allow experimentation and research analysis,
	including the ability to export sanitized logs, job data, and
	the ability to run experimental features within the Resource
	Manager framework. \\
  \hline
  \textbf{Generalized} & Resource Manager will attain maximal flexibility
	by abstracting resources as much as possible. i.e., a compute node
	is a pool of resources, a cluster is a pool of resources, a center
	is a pool of resources, where a resource can be a consumable or a
	collection of such consumables. \\
  \hline
  \textbf{Integrated} & Resource Manager will allow easy integration with
	other tools and frameworks, including monitoring, logging, and
	remote execution. \\
  \hline
\end{tabular}

\subsection{Architectural Components}\label{ReqsArch}

\begin{tabular}{|p{4cm}|p{12cm}|}\hline
  \textbf{Scheduler} & The Scheduler manages the priorities of a queue
	of jobs requesting access to resources controlled by NGRM.\\
  \hline
  \textbf{Resource Manager} & Tracks resources available in the system and
	arbitrates access to these resources.\\
  \hline
  \textbf{Remote Execution} & Handles launch of processes across one or
	more resources managed by NGRM, including authorization,
	authentication and management of IO, environment, etc..\\
  \hline
  \textbf{Monitoring/Logging} & Manages collection and storage of monitoring
	and log data across the NGRM.\\
  \hline
  \textbf{Provisioning} & Manages root and other filesystem images across
	the NGRM.\\
  \hline
  \textbf{Communications Network} & Network channel through which all
	components of NGRM communicate.\\
  \hline
\end{tabular}

\subsection{High-Level Functional Requirements}\label{ReqsHiLevFun}

\begin{longtable}{|p{1cm}|p{15cm}|}\hline
  \multicolumn{2}{|l|}{1. \textbf{Zero Downtime}} \\
  \hline
  1.1. & Scheduled upgrades of NGRM components shall not require a downtime.\\
  \hline
  1.2. & The NGRM shall incorporate fault tolerance at every level, so
	that a failure of one component does not affect functionality of the
	system as a whole.\\
  \hline
  1.3 & The NGRM shall support version interoperability, so that the
	deployed system as a whole is not required to be at the same level
	of software.\\
  \hline
  \multicolumn{2}{|l|}{2. \textbf{Efficient Center-Wide Resource Management}} \\
  \hline
  2.1 & The NGRM shall have the ability to function as a single instance
	managing all clusters within a network. \\
  \hline
  2.2 & The NGRM shall be able to efficiently display a global view of
	resources to users when running in the mode described in R2.1.\\
  \hline
  2.3 & The NGRM shall support the specification of generic resources such
	as GPUs, IO Bandwidth, Power, etc in addition to CPUs, Memory,
	and nodes. \\
  \hline
  2.4 & The NGRM shall allow the hierarchy of resources to be specified in
	configuration or during discovery. For example, the definition of
	a node should allow the topology of that node to be recorded in
	the NGRM configuration (i.e. which CPUs are in which sockets,
	NUMA placement of memory, etc.) Similarly, there shall be the
	ability to record/discover the topology of nodes within a cluster,
	location and bandwith to IO storage from those nodes, access to
	and number of licenses, etc. FIXME: This needs rewording\\
  \hline
  2.5 & The NGRM shall support allocation of "interactive" resources from
	the compute pool, allowing more intelligent and dynamic creation
	of "login" nodes\\
  \hline
  2.6 & The NGRM shall support resource "tags" (similar to existing features)
	that can be applied to any resource, and a method to allow users
	requesting resources to select from tags\\
  \hline
  \multicolumn{2}{|l|}{3. \textbf{Integrated Monitoring and Logging}} \\
  \hline
  3.0 & NGRM monitoring and logging shall be designed to reduce system noise
	as much as possible\\
  \hline
  3.1 & NGRM shall provide an integrated monitoring plugin API to allow
	system monitoring to be extended to handle future requirements.\\
  \hline
  3.2 & NGRM shall provide the ability for users to tune the level of
	monitoring on the nodes of their jobs, allowing users to decrease
	monitoring levels and/or intervals for noise-sensitive jobs, or
	increase levels if they so choose.\\
  \hline
  3.3 & NGRM system monitoring events on resources connected with a particular
	job (including file systems) shall be made available to users
	monitoring their job or in post-mortem reports or queries.\\
  \hline
  3.4 & NGRM job log data shall have a public interface usable by tools
	such as sqlog to avoid duplication of data.\\
  \hline
  3.5 & NGRM job log and system monitoring data shall be made available in
	sanitized form for use in job scheduling research, simulator testing
	of NGRM releases, etc.\\
  \hline
  3.6 & NGRM job log and system monitoring data shall be collected,
	annotated, and saved to facilitate failure analysis.\\
  \hline
  3.7 & NGRM shall provide a library that can be linked to user codes that
	will collect and store generic key/value pairs.  This would replace
	LLNL's tracker tool and LANL's reportjob tools.\\
  \hline
  \multicolumn{2}{|l|}{4. \textbf{Communication Network}} \\
  \hline
  4.1 & NGRM components shall exchange messages and route log and monitoring
	data through a heirarchical, fault tolerant network.\\
  \hline
  4.2 & NGRM network shall support messages, streaming data, and RPCs\\
  \hline
  4.3 & NGRM network shall support privacy, integrity, and authentication\\
  \hline
  4.4 & NGRM network shall export a API for use by tools and users to reuse
	established global and job-wide communication hierarchy.\\
  \hline
  \multicolumn{2}{|l|}{5. \textbf{Remote Execution}} \\
  \hline
  5.1 & NGRM shall provide a service for remote parallel execution across
	jobs for users as well as globally for administrators\\
  \hline
  5.2 & NGRM remote execution service shall have the ability to manage
	instantiation of private namespaces for jobs\\
  \hline
  5.3 & NGRM remote execution shall allow transport of all process environment
	attributes including environment variables, resource limits,
	namespace attributes, etc.\\
  \hline
  5.4 & NGRM shall have the ability to bootstrap specialized environments
	such as a copy of NGRM itself (recursive execution), or an instance
	of \slurm\ (for backwards compatibility), or other frameworks such as
	Hadoop.\\
  \hline
  5.5 & NGRM shall support launch of MPI jobs up to 100,000 nodes with an
	arbitrary number of tasks per node.\\
  \hline
  \multicolumn{2}{|l|}{6. \textbf{Provisioning}} \\
  \hline
  6.1 & NGRM shall separate user and system execution envioronments by
	running within a minimal "core" system root, and invoking all jobs
	within separate (possibly user-selected) root filesystem\\
  \hline
  6.2 & NGRM shall provide service to allow users to run jobs with
	filesystem configuration of their choosing using private namespaces.
	The filesystems will need to be mounted without setuid for security
	purposes.\\
  \hline
  \multicolumn{2}{|l|}{7. \textbf{User Interface}} \\
  \hline
  7.1 & The NGRM shall export a rich API from which to build user interfaces.
	Command line as well as web based interfaces should be feasible with
	this API.\\
  \hline
  7.2 & NGRM should support a centralized data store for management and
	analysis of system usage. The store should support highly concurrent
	and frequent accesses in as close to real time as possible without
	affecting job performance. A memory-based database supporting a
	pub/sub mechanism, such as Redis, would be ideal. (Jeff Long,
	Joel Martinez)\\
  \hline
  7.3 & NGRM should provide an HTTP based REST API. Ideally the API would
	support a variety of different data formants (JSON, XML, etc...).
	The API should be implemented with a single-sign-on solution or
	API key implementation to avoid the need for additional user
	authentication. (Jeff Long, Joel Martinez)\\
  \hline
  \multicolumn{2}{|l|}{8. \textbf{Scheduling}} \\
  \hline
  8.1 & The Scheduler in the NGRM shall operate as a plugin or separate
	process or other easily replaceable component.\\
  \hline
  8.2 & The Scheduler API shall have a clean interface such that the
	scheduler does not need to be upgraded/developed in lockstep with
	the NGRM core\\
  \hline
  8.3 & The Scheduler interface in the NGRM shall allow the scheduling
	implementation access to all resources information gathered by
	the RM, including topology, heirarchy, data locality, IO bandwidth,
	etc.\\
  \hline
  8.4 & When running in recursive mode (e.g. see 5.3), the user should be
	allowed to select from a list of alternate scheduler implementations
	or even provide their own.\\
  \hline
  8.5 & NGRM scheduler shall support high job throughput\\
  \hline
  8.6 & NGRM shall support overlapping resource partitions (queues)
 	NGRM scheduler shall support complex job dependencies\\
  \hline
\end{longtable}

\subsection{Use Cases}\label{ReqsUseCases}

\begin{longtable}{|p{1cm}|p{15cm}|}\hline
  UC1 & \textbf{Use NGRM recursive execution to manage dedicated application
	test time}\newline
	Currently a DAT (dedicated application test) is managed
	by draining an entire cluster and then "giving" the test team access
	to the cluster via support staff with expedite privileges. With
	NGRM recursive execution, the DAT could be submitted to the RM as
	a job with constraints to run on all or part of a cluster. Once the
	job has been allocated on the cluster, team members would instantiate
	interactive instances to the job, and the recursive feature of NGRM
	would make it appear as if they had access to an empty cluster. Jobs
	could then be submitted to this instance from within the original
	NGRM job or the users' interactive instances. This scenario is also
	useful for testing new versions of the NGRM or other system software.\\
  \hline
  UC2 & \textbf{Sysadmin ability to "drain" only a portion of the resource
	hierarchy}\newline
	Currently, the resource management "drain" functionality is limited
	to a single node. Consider a case where a resource within a node goes
	bad, e.g. a GPU. Since the rest of the node is fine, the NGRM should
	allow just the GPU resource to be "drained" and the rest of the
	node is usable for compute jobs that do not need a GPU resource.
	When draining a full node or group of nodes, all the resources within
	the hierarchy of those nodes should also be drained. This would also
	allow an entire cluster or subset of resources to be drained by
	draining at the top level "cluster" resource.\\
  \hline
  UC3 & \textbf{Power utilization as a resource}\newline
	As a datacenter manager I want to deploy a cluster and provision less
	power to it than the max theoretical peak. The NGRM should allow the
	total available power to be specified at the cluster and/or PDU level
	within the cluster, and should treat power as a consumable resource.
	The NGRM will ensure that the set of resources use only the power that
	has been budgeted. If realtime power utilization is available, then
	those values can be aggregated and used (though this may not be safe
	when applications with fluctuating power demands are running),
	otherwise the NGRM should allow some kind of power utilization model
	to be registered (e.g. 90W per cpu + 100W per GPU + 200W base
	utilization per node...)\\
  \hline
  UC3.1	& \textbf{Energy usage part of job report}\newline
	The total energy consumed by a job should be reported upon job
	completion. (Barry Rountree)\\
  \hline
  UC3.2	& \textbf{Track power efficiency of components}\newline
	CPU's have varying power efficiency. Periodically measure this and
	record in resource db to be combined with a static power model.
	Also, scheduler could use this info to schedule the fastest nodes
	to the critical path. (Barry Rountree)\\
  \hline
  UC3.3	& \textbf{MPI runtime able to set power MSRs}\newline
	The MPI runtime can identify slow ranks and adjust power clamping
	to gain more performance. Application-driven variation in power
	consumption must not exceed breaker trip levels in a system plumbed
	for less than peak power consumption. (Barry Rountree)\\
  \hline
  UC3.4	& \textbf{Provide ability for job to specify power ranges}\newline
	User should be able to specify the maximum (and minimum?) power their
	job will consume.  Scheduler will only schedule job when it can
	configure the resources to remain within the specified power envelope.
	(Barry Rountree)\\
  \hline
  UC3.5	& \textbf{Node vs. Time Scheduling becomes Power vs. Time}\newline
	See M. Etinski paper\cite{PowerOpt} (Barry Rountree)\\
  \hline
  UC4 & \textbf{Generic aggregate resources}\newline
	As a generic case of UC3, imagine a resource that is distributed
	across nodes or a whole cluster. A contrived example might be
	bandwidth to a SAN or other storage pool. The NGRM should have the
	ability to account for, manage, and schedule such generic resources
	in a way that is extensible to unforeseen resources, since we cannot
	imagine all possibilities beforehand. The NGRM should offer the
	ability to develop plugins or helpers to enforce and monitor and
	display these aggregate resources.\\
  \hline
  UC5 & \textbf{Center-wide cron}\newline
	As a sysadmin I may want to schedule a periodic job to run on
	systems of a certain type, so the NGRM should have cron-style
	capabilities at the center level. A cron "job" should be registered
	in the queue or in configuration that is run by the NGRM on the
	specified interval, on nodes matching the resource constraints
	specified in the "job". Cron work scheduled on compute nodes, such
	as required NAPS tests, should be run through NGRM such that they
	do not create OS jitter for running jobs. For example, they could
	only run between jobs or if they must run during a job, they could
	run synchronized. Users should be able to submit cron jobs too (at
	least some users like hotline do this).\\
  \hline
  UC6 & \textbf{Live user feedback for job progress}\newline
	As a user I would like access to resource manager data live while my
	job is running as a sort of job progress indicator. It would be useful
	to have IO statistics (perhaps with built-in IO Watchdog
	functionality), power utilization, network bandwidth, and the ability
	to register handlers if no progress is detected (by my own definition
	of no progress detected).\\
  \hline
  UC7 & \textbf{Allow users to inject application specific data into
	data stream for jobs}\newline
	As a user it would be really useful if I could inject application
	specific data into the data stream for a job. The job database could
	then keep this data in perpetuity, instead of having me keep data
	about my runs in an ad-hoc fashion. Data should be free form to allow
	for the greatest usability. Examples might be name of code, run ID,
	and iterations as they occur with timestamps. This would be useful in
	conjunction with UC6 as well.\\
  \hline
  UC8 & \textbf{dsh|dshbak}\newline
	As suggested by req. 5.1, pdsh|dshbak would be submitted via NGRM.
	There should be a way to limit concurrency (like pdsh fanout), a way
	to select specific hostnames (like pdsh wcoll), and a way to submit
	the dshback such that output is reduced in a distributed fashion
	(e.g. on intermediate nodes of the comms tree).\\
  \hline
  UC9 & \textbf{User control over system software levels}\newline
	As a user, for testing or reproducible results, I want to the ability
	to rerun a job or set of new jobs under a previously supported level
	of system software. I do not want to be required to record important
	system software versions manually, so the resource manager should
	track this data for every run and keep a record in a historical
	database so that I can go back and determine what software level
	was running when any one of my jobs ran.\\
  \hline
  UC10 & \textbf{Testing system software releases}\newline
	Major system sofware releases (e.g. TOSS major releases that break
	binary compatibility with old releases) should be testable in advance
	of being configured as the default through NGRM option at run time.\\
  \hline
  UC11 & \textbf{Integrated tool support}\newline
	NGRM should be able to efficiently launch and tear down STAT,
	totalview, and other distributed tools with a presence on compute
	nodes. NGRM should provide hooks for those tools so they can avoid
	reimplementing NGRM features. (See also MPI 3.0 Tools Support WG de
	Supinski, Schulz)\\
  \hline
  UC12 & \textbf{Allocate spare resources from a common pool}\newline
	Support a "spare resources" model whereby fault tolerant MPI jobs
	could dynamically pull in replacement nodes or other resources from
	the common pool rather than allocating spare resources privately at
	job submission.\\
  \hline
  UC13 & \textbf{Checkpoint/restart}\newline
	Support user-level checkpoint/restart such that NGRM can signal a
	job to begin checkpointing, receive an acknowledgement when
	checkpointing is complete, manage the checkpoint data (ensure it is
	on stable storage), clear the job from the system, then at a later
	time, stage in the checkpoint data and restart the job. (See also
	BLCR, SCR, OpenMPI c/r).\\
  \hline
  UC14 & \textbf{Ephemeral file system instances}\newline
	Allow user to request a dedicated parallel file system to be
	instantiated for the life of their job. NGRM could allocate disks
	from pool of storage resources, optionally stage data on/off of this
	file system at setup/tear-down.\\
  \hline
  UC15 & \textbf{Integrated I/O forwarding support}\newline
	Set up and tear down I/O forwarding daemons for exclusive use by
	a job. Allow flexibility in the number and placement of such daemons
	and their mapping to compute nodes. Collect I/O statistics from
	daemons and make available as part of job monitoring stream/records.\\
  \hline
  UC16 & \textbf{Hadoop framework}\newline
	NGRM should be able to launch hadoop framework on allocated resources
	(including storage).\\
  \hline
  UC17 & \textbf{User database instances}\newline
	NGRM should support starting a database server such as MySQL on
	allocated nodes/storage, loading a data set, and running a series of
	jobs that use the database, in some way telling the jobs how to
	connect to the server, and managing access.\\
  \hline
  UC18 & \textbf{Detect and report out of spec components}\newline
	As suggested by req. 3.6, NGRM should make it easy to detect when
	hardware / software components are performing out of spec or isolate
	components common to failed jobs.\\
  \hline
  UC19 & \textbf{Record HW configuration}\newline
	NGRM should record known HW configurations for each job executed.
	The data should have an schema-less, self-describing format to
	facilitate future previously unknown hardware configurations.\\
  \hline
  UC20 & \textbf{Provide "pre-job" resource information}\newline
	Users or admins should be able to query resource information such as
	network topology, I/O bandwidth, CPU speed, node memory, etc.
	This allows for users to alter jobs for "optimum" execution.
	For example, MPI communications algorithms or requested node
	allocation could be changed based on network topology.\\
  \hline
  UC21 & \textbf{Virtual private networks for jobs}\newline
	It should be possible to run a job in a virtual private network
	environment separate from that of the NGRM software, such that the
	job's network access is restricted to resources appropriate for it
	to access. This could be used to manage access to private services,
	such as the database in UC17. It might also be possible to organize
	user communities and their file stores such that the same protection
	offered by a firewall could be achieved without partitioning stateless
	compute resources.\\
  \hline
  UC22 & \textbf{Verbose Logging Triggered by Fault Event}\newline
	The monitoring system should facilitate capturing verbose debug logs
	prior to a fault event. One way to do this is with a circular trace
	buffer that is dumped into the monitoring stream on notification of
	a fault. (See "self propelled instrumentation", e.g. paradyn project)
	(Kathryn Mohror, Don Lipari)\\
  \hline
  UC23 & \textbf{I/O Staging}\newline
	The user should be able to specify files at job submission time that
	will be moved to storage close to compute nodes in advance of job
	launch. Files could be directed to be moved the other direction
	after job termination. This should be done in a way that does not
	impact other jobs, and can occur concurrently with allocating/freeing
	other job resources that aren't involved in moving files (Kathryn
	Mohror)\\
  \hline
  UC23 & \textbf{Give me a fat node for rank 0 and top it up with thin or fat ones}\newline
	In sbatch to ask for a fat node (more memory) and then a couple of
	other nodes (fat or thin), and then have the batch script start on
	the fat node, so that rank 0 is placed there by default by the MPI.
	(Kent Engstrom request to slurm-dev)\\
  \hline
\end{longtable}
