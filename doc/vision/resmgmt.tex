\section{Resource Management}
\label{sec:resmgmt}

\subsection{Overview}

At a high level, we designate the \emph{Resource Management} (RM)
thrust as concerning the configuration, scheduling, and
tracking of resources, jobs and users in the \ngrm\ system. The
RM  thrust is a key component of \ngrm\ because it embodies the
user interface to a site's resources and offers the capabilities
for users to submit jobs and thus do useful work with those
resources. Therefore, it is paramount that the RM components of
\ngrm\ not only be generalized, flexible, and extensible, but
also \emph{powerful} and \emph{user-friendly}.

In this section, we will discuss the
components of \ngrm\ that provide our resource managemnt
interface and functionality. With these components, we
aim to fulfil the  goals described above and in
Section~\ref{sect:projorg}. We will start by describing our plan
for a powerful, extensible domain-specific language for use in
describing resources and requests for those resources. We will
continue by outlining the design of a set of global databases that
will be used by our RM software for configuration and historical
data. Next, we will describe the architecture and functionality
of a \emph{job} within \ngrm's unified job model, and how jobs
will interact between parents and children within the resource
management domain. Finally, we will discuss a flexible interface
for job scheduling within the \ngrm\ job, and some details about
job scheduling implementations in the new system.

\subsection{Resource Description Language}

In any resource management system there must be a method by
which the configuration of resources are communicated to the
system. Typically this functionality is achieved via some form
of static configuration, that is via a text file or database
that is created manually or with the help of some kind of
tool. In kind, users need to describe the resource \emph{constraints}
for their jobs in some form -- typically via a combination
of command line options, features requests, and or using
some sort of resource specification language such as the
Globus RSL~\cite{GlobusRSL}.

For \ngrm\ we propose a single resource configuration and
specification language simply termed the resource description
language (RDL).  The RDL shall be a Domain
Specific Language (DSL) that will be used to describe the
hierarchical configuration, topology, and other data about
resources in the system. The language will be structured, extensible,
human-readable, and hierarchical, while being capable of
representing resources and their relationships in a generic and
flexible fashion. It is expected that this language will serve not
only as the base \emph{configuration language} of \ngrm, but that
this language will be the de-facto communication substrate for
gathering resource information such as topology, current resource
state, categorization, as well as constraint specification in
resource requests.

\subsubsection{Related Work}

Fortunately, there exists a large body of literature in this
field on which we can draw when designing the RDL for \ngrm.
While our pragmatic design may not focus on ontological formalism,
there has been work in this area for describing distributed resources
in a Grid~\cite{Castano:2004, Pernas:2005, Koning:2011:UOR:1998662.1998819}
which show promise for semantic matching algorithms on generic resources.
Van Der Ham et al.\ and others have extended the Resource Data Framework (RDF)
specification from the semantic web to describe networked resources
\cite{vanderHam:2006:URD:1160256.1160260, VanDerHam:2008:DTI:2285568.2285672, vanderHam:2006:SHN:1188455.1188643},
and Koslovski et al.\ have developed the Virtual Resources and
Interconnection Networks Description Language (VXDL)~\cite{Koslovski_Primet_2009} for use in
describing the end resources description and virtual network
topology in on-demand virtual infrastructures.

Several other resource management projects have also explored this
area. Possibly most importantly, the Condor project implements
\emph{Classified Advertisements} (ClassAds) which is a language
for expressing not only resources and their attributes, but
requests for these resources~\cite{ClassAd}. The suitability
of resources for resource requests (jobs) are matched using an
array of multi-dimensional gangmatching approaches. The ClassAd
language is available as a standalone library. Additionally, the
OAR resource manager defines resources in a MySQL database with
a static schema, but it does organize resources hierarchically,
allows generic resource definition, and allows users to request
resources using a resource description language~\cite{Oar}, and
the Legion~\cite{LegionGrid,LegionRM} Resource Manager uses an
object-oriented approach for defining resources as ``objects''
that are extensible. Another example is CCS~\cite{Keller98ccsresource},
which implemented the Resource and Service Description (RSD)
language and its predecessor the resource description language (RDL).
The RDL in CCS exports not only a language interface for resources
description, but a graphical user interface and API as well.

As part of the design our RDL, it is expected that we will do a
more complete survey of existing work in this area such that we can
apply common practice and lessons learned to our own implementation
of a resource description and configuration language.

\subsubsection{Resource Description Language Design}

As mentioned above, as part of \ngrm\ development we hope to
create a domain-specific language that is
easily extended and embedded, is human readable, and has the
power to express our hierarchical resource data, topologies,
and advanced resource constraints. The RDL should additionally
have to ability to contain the topology of resources
(which may be different than the heirarchy of the resources).

While a suitable existing encoding may be discovered during
a full literature search, it is our feeling that a solution
based on a static data description or markup language like
RDF or XML is not going to have the ultimate flexibility and
features that we require in the \ngrm.  For this reason, we
currently propose that the Lua~\cite{LuaBook}
language would be a good fit for our requirements.

Lua is a language that was designed to be embedded in other
languages, so it would be easy to embed parsers for the RDL
in various tools. It is also embarassingly easy to extend the
language using modules or directly in native Lua. Finally,
the core datatype in Lua (in fact the only datatype), is
the Lua \emph{table} (an associative array), which lends
itself nicely to the expression of hierarchical data as
we have noted will be necessary for the RDL in \ngrm. There
are many extant examples of the use of Lua as a Data Description
and Domain Specific Language. See the Programming in Lua (PiL)
Book~\cite{LuaBook} for examples.

\begin{lstlisting}[
 float=*htp,
 frame=shadowbox,
 %rulesepcolor=\color{gray},
 numbers=left,
 numbersep=5pt,
 numberstyle=\tiny\sffamily,
 basicstyle=\scriptsize\tt,
 caption={A na\"{\i}ve example of a Lua table describing an excessively simple resource hierarchy},
 captionpos=b,
 label={lst:luaex1}]
ComputeNode = {
  type = 'host',
  attributes = { hostname = '', ipaddr = '', memory = ''},
  children = {
     { type = 'NUMANode',
       id = '0',
       children = {
          { Type = 'Memory', id = '0', value = 16384 },
          { Type = 'Socket', id = '0',
	    children = {
	      { Type = 'CPU', id = '0', children = {}},
	      { Type = 'CPU', id = '1', children = {}}
	    }
	  },
       },
     },
     { type = 'NUMANode',
       id = '1',
       children = {
          { Type = 'Memory', id = '1', value = 16384 },
          { Type = 'Socket', id = '1',
	    children = {
	      { Type = 'CPU', id = '2', children = {}},
	      { Type = 'CPU', id = '3', children = {}}
	    }
	  },
       },
     },
     { type = 'GPU', id = '0' },
  }
}
\end{lstlisting}


Listing~\ref{lst:luaex1} shows a very simple example of
a Lua table used to describe a hierarchy of resources within
a compute node. Note that the attributes of the node resource
are currently left empty, to possibly be filled in as the
table is copied and appended to the {\tt children} table
of another resource, such as a cluster. Used in this fashion --
as a data store -- a Lua table is very similar to JSON, another
popular data interchange format.

It is not expected that the RDL in \ngrm\ will use the na\"{\i}ve
approach as in Figure~\ref{fig:luaexample1}. Because Lua is a full
language instead of just a data interchange format, there will be
many optimizations and syntactic abbreviations we can make to ease
working with and using the \ngrm\ RDL.

For example, we expect to use the \emph{object inheritance} support
in Lua to allow resources definied within the RDL to inherit from
other resources. This should support collaboration and research
by allowing sharing of resource definitions as RDL ``libraries''
or resource definition sets. For example, a base type might be
a {\tt Node} class which implements a set of interfaces that are
common to all types of nodes (such as \emph{has a} hostname, ip
address and so on). Specific types of nodes can inherit from the
base node object and add features (such as specialized devices,
default tags etc).

Additionally, with the power of a full language at their disposal,
system managers and users can develop a range of scripts and
extensions that ease working with data in the RM system. For
example, a sysadmin could write a script to create the definition
of an entire cluster by reading a comma-separated value text file,
or other formatted data.

The risks of using a full language like Lua as the RDL for \ngrm\
are also numerous. Since the RDL will be used for resource
requests and definitions, priviliged code within our RM system
may be compiling and running untrusted code. While Lua has very
good native support for sandboxing~\cite{LuaSandbox}, this is
a notoriously difficult practice to get right, and code using
the RDL may need to be hardened extremely well for any use in a
production environment. Evaluation of user-supplied code should
be done within unprivileged processes as much as possible. Also,
when using a dynamically typed, runtime-compiled language like Lua,
there is an increased risk of runtime exceptions, so extra care
must be taken to handle errors correctly, and it is likely that
a specialized "RDL validation" function must be written.

\subsection{Global, Persistent Data in \ngrm}

In the \emph{Unified Job Model} of \ngrm\ we combine the concept
of a traditional job with the idea of a resource management
\emph{instance} which provides the traditional features of a
resource manager and batch scheduler. However, the top-level
\emph{root job} in such a system will need to be initialized from
somewhere. Additionally, in order to be useful, the RM system will
need some sort of persistent record of jobs that ran on the system,
for how long, and on which resources.

To satisfy these requirements, we introduce the global, persistent
\emph{Resource Inventory} and \emph{Job and User Repositores}. These
facilities operate outside of the \emph{hierarchical job model} in
\ngrm\ and act as a source of ultimate configuration and historical
data about the RM system. Each of these facilities is described
in more detail in the sections below.

\subsubsection{Resource Inventory}

As noted above, the Resource Inventory is a global, persistent
database which acts as the top-level configuration for all
jobs within the \ngrm\ system. The resource inventory itself
will support being initialized, modified, and queried using
the RDL, and thus will be optimized for the storage of hierarchical
resources and their topology.
\ifcomments
\marginpar{\tiny
{\bf how} to store hierarchical data and topology information
together is a subject for further research.}
\fi

To satisfy our generalized resource model we must strive to build
a resource inventory that is itself generalized and flexible.
To this end, we propose that the resource inventory implementation
support arbitrary \emph{tagging} of resources. Resource tagging
is a more general approach than the practice of giving nodes
features or properties as in traditional resource managers. We also
propose that the tagging approach is powerful enough to support RM
features such as marking resources \emph{down} or \emph{drained},
an even \emph{allocated}. Furthermore, it is common practice for
tagging databases to allow users to supply their own tags to data
in the system. Use of this kind of \emph{collaborative tagging}
or folksonomy~\cite{wiki:folksonomy}, could be very useful in
creating a socialized system of resource management.

In order to enable the development tools around the resource
inventory, and to support notification of resource changes and
reconfiguration to jobs in the \ngrm\ system, we propose that
the resource inventory export a \emph{subscribe} interface in
addition to a more traditional API. The subscribe interface will
support filtering so that tools (and jobs) can get notifications
of specific changes (perhaps to a subset of resources, or changes
to a particular tag). For instance, the root job in \ngrm\ will
subscribe to the resource inventory to get updates to resources,
such as resources that are drained or modified.

\subsubsection{User Repository}

Since \ngrm\ is a software system that will be used to provide
\emph{users} with access to compute resources, it will require
some place to store information about those users. For this
purpose, we will require a database of user information alongside
the resource inventory. We call this global, persisten user
data store the \emph{user repository}.

At the very least, the user repository will store minimal
data about users of the current deployment of \ngrm. However,
the implemntation should be flexible enough to allow the storage
of other user-specific information, such as defaults, limits,
roles, accounts, qualities of service, and so on.

\subsubsection{Job Repository}

The \emph{job repository} is the final global and persistent
data store in the \ngrm\ system. This top-level database is a
historical record of all jobs that have completed in the
\ngrm\ system. Along with the obvious data about a job --
the start and end times, the resources assigned to the job,
and the owning users -- the \ngrm\ job repository will also
store a complete provenance record for the job. The provenance
record will (configuration permitting) contain data such as the
job environment, namespace or list of installed packages, fault
stream and other job-specific monitoring data. It may also be
beneficial to store other job information such as input files
and stdin/stdout streams, so the job repository will not be
designed with a rigid schema.

Another challenge in designing a job repository for \ngrm\ is
storing job data from the \emph{hierarchical job model}. Similar
to the resource inventory, the job repository will need to be
optimize to store hierarchical data. The intent of the job
repository is to store \emph{all} job data, down to even the
lightweight job invocations in the leaf jobs of the system,
so there will be a mass of hierarchical data here. Developing
a system that not only efficiently represents that hierarcy,
but allows advance and intuitive queries for the data should
be a top priority.

\subsection{Definition of Resource Management}

One of the main goals of \ngrm\ is to create a RM system
that is {\em extensible}, {\em scalable}, and {\em
generalized}(\ref{ReqsHiLevFun}). To meet these goals, we
build our resource manager on a set of components that are
themselves extensible and generalized. It is intended that
these components form a framework upon which a useful RM
subsystem is implemented. The core components of this system,
which are described in detail below, include a set of global,
persistent databases called the {\em Resource Inventory} and
{\em Job} and {\em User Repositories}, which contain the global
configuration of resources, users, and historical job data. Within
an \ngrm\ job, these databases are not persistent, and are instead
implemented as lightweight versions called simply the {\em resource
database} (RDB), {\em job database} (JDB), and {\em user database}
(UDB). Running within a job, we call a functioning collection of
these databases, and the interface to them a \ngrm\ {\em instance}.
(See Figure~\ref{RMInstance}).


\begin{figure}
\centering
\includegraphics[scale=0.30]{../fig/RM-instance.eps}
\caption{Components of a Resource Manager Instance}
\label{RMInstance}
\end{figure}

A high level view of these components is presented in Figure~\ref{RMComponents}.

\begin{figure}
\centering
\includegraphics[scale=0.20]{../fig/RM-full.eps}
\caption{Resource Manager High Level View}
\label{RMComponents}
\end{figure}

In \ngrm\ users requesting resources, administrators configuring
or operating on resources, or subsystems utlizing resources
must have a flexible and extensible method for describing those
resources.  To meet this goal we introduce the idea of a {\em
resource description language} (RDL) in the sections below. We
also discuss a similar {\em job description language} (JDL) which
is used to encode generic job information in \ngrm. In \ngrm\
we consider that the Resource DB and Inventory {\em speak} RDL
and the Job DB and Repository {\em speak} JDL.

Finally, with these components in place, we discuss how we will
build a {\em Scheduler} in \ngrm. The Scheduler is a core component
of an \ngrm\ instance as it is responsible for building the schedule
that maps resource requests to time slots and resources, and thus
implements the essential functionality of the system -- that is the
efficient use of limited resources across a diverse user base while
implementing site policy.

\subsection{Repository Design}

The job and user repositories and resource inventory Only exist
at the same level as the resource inventory. That is, since they
are persistent, they cannot be tied to any one "job". Instead,
these are all global databases with one a common API.  They are
accessible from any job and/or user workstation via globally
routable server name and port for example.

Within any job, there is a "simpler" implementation of each of these
databases that we just call the (job-local) resource, user, and job
databases (as indicated in Figure~\ref{RMComponents}).  In this case,
these databases are instantiated on an as needed basis, and they may
be implemented as rw cache of the same databases in the parent. In
this case, "instance 0" has a parent of the global, persistent
databases -- the resource inventory, and job and user repo.

All of these components provide a pub/sub interface such that children
watch for interesting changes in their parent, and parents watch for
interesting changes in the child. "Interesting" changes in this case
might be important data about resources in the child (this resource is
dead), or information about the child job itself (I'm dead).

We will adopt the model from UNIX process management and have the
parent instance "reap" its children. It is here that the job db from
the child can be "pulled" up from the child into the parent job db.
When instance 0 reaps jobs, this job data can be pushed up to its
parent, i.e. the persistent job repo.

(TBD -- how to store child job information in the parent such that the
historical lineage of the jobs and sub-jobs within the child are
preserved.  Maybe the reaping should be abstracted down in the comms
layer with callbacks to allow the higher level subsystems to reap
their analogs in children.)

In this model, historical job data makes its way up to the top-level
job repository as child jobs complete. Each "running" job instance has
information about its historical job lineage in its local job db, so
this information can also be queried directly from within the context
of a job. (e.g. in a DAT, if you want to only query information about
jobs from the DAT, you can query the DAT job instance. In fact,
information about jobs from the DAT are not populated to the top-level
job repository until the DAT "ends")

We will define how jobs indicate that they are "done" and need to be
reaped. A DAT "job" may need to be killed and reaped at the end of its
time limit. Normal batch jobs are complete when the batch script
running on the control node exits. A direct allocate/launch with WRAP
would be reaped when the processes being launched exit. (Any other
cases?)

(TBD -- What happens to an active job hierarchy when the top-level job
is killed?  What happens to pending job requests when a job is
terminated?  Killing a job might result in something like:

\begin{enumerate}
\item Freeze local job db (i.e. disallow new job submissions)
\item Terminate and reap children jobs
\item Kill local tasks
\end{enumerate}

Perhaps 2,3 could be swapped or done in parallel.)

\subsection{Job Scheduler}

The \ngjs\ is responsible for scheduling computing resources to users'
jobs.  Users submit to the scheduler requests for resources to run
their job.  The scheduler implements management's policy to decide
when and where to allocate the resources for each job.

This section summarizes the requirements for the \ngjs, a rough design
which meets those requirements, and a work breakdown structure for
developing the scheduler component.

\subsubsection{Motivation}

Scheduling batch jobs across a collection of networked computing
resources started in the 1990's with Livermore Computing's DPCS (later
known as LCRM).  It received users' job requests, selected a cluster
for each job, then dispatched the job to that cluster's resource
manager.  The Moab Workload Manager which replaced LCRM essentially
provided the same functionality.  And while SLURM provides some grid
functionality, it never matured enough to allow it to replace Moab for
production use.

The \ngjs\ represents a departure from traditional monolithic ``grid
masters''.  The scheduler functionality will be a service provided by
the \ngrm's job model.  As such, the scheduling activities will be
distributed across the center's resources and provide functionality
not available in any commercial or open source project.

\ngjs's scheduling services will schedule jobs across resources in a
computing center without regard to current cluster boundaries.  A job
will be able to request resources containing a common feature (like
connectivity to the same high speed switch) or fitting within a
limited power envelope.

The \ngjs\ will support plugin modules that provide unique scheduling
behavior and job prioritization.  Each job will have the option to
independently load its own scheduling plugin.  In so doing, the
\ngjs's scheduling capabilities will range from scheduling all
resources in the center to scheduling jobs on dedicated resources
(DATs) to scheduling LWJ's (job steps).

Most importantly, the traditional boundaries between a job scheduler
and the resource manager will be redefined under \ngrm.  Instead of a
resource manager that manages every resource of a cluster, the
resource management services will be instantiated as part of the job
and be restricted to only the resources allocated to the job.

In order to continue to meet the needs of LC users, the \ngjs\ must
continue to provide all the services that our current schedulers
provide.  Our goal is to surpass our existing schedulers in the
following areas: performance, accuracy, reliability, resiliency, ease
of use, flexibility, security, diagnostics, and need for manual
intervention.

\subsubsection{Requirements}

While a more detailed list of requirements is presented in
\ref{ReqsHiLevFun}, the following provides an overview of the
functionality that the \ngjs\ will be expected to deliver.

\paragraph{Fundamental Requirements}

The following is the most definitive list of basic scheduling
requirements.  The job and resource repositories as well as the job
submission facility are external to the \ngjs.

\begin{itemize}
  \item Prioritize each job
  \item Schedule each job based on its resource requirements
\end{itemize}

\paragraph{Further Scheduler Requirements}

In addition, more elaborate scheduling plugins will be provided to do
the following:

\begin{itemize}
  \item Support complex job dependencies
  \item Backfill lower priority jobs whenever possible
  \item Facilitate dynamic job growth and reduction
  \item Preempt running jobs to free up resources needed by higher priority jobs
  \item Calculate estimates of when each job will begin
\end{itemize}

\paragraph{Policy Enforcement}

\ngrm\ implements the center's policies for providing access to its
computing resources.  The following are responsibilities,
traditionally associated with a batch scheduler, that will be borne by
the larger \ngrm\ system:

\begin{itemize}
  \item Reject job submissions for jobs which cannot or will never run
  \item Remove jobs that exceed time limits
  \item Enforce established limits on users, groups, projects (banks), etc
  \item Honor service level agreements and service quality requests
\end{itemize}

\paragraph{Organization Components}

The \ngjs\ functionality is broken down into the following components.

\textbf{Job Prioritization.}  This the facility for prioritizing jobs
based on potentially multiple factors.  The system shall offer a job
priority plugin framework to allow custom algorithms for determining
job priority.  The priority of each queued job must be continually
recalculated as the queue of jobs and workload factors change.

\textbf{Job Scheduling.} For each job removed from the prioritized
queue, computing resources must be reserved and eventually allocated.
The collection of resources to schedule must be available from the
resource inventory with the state and status of each resource updated
in real-time.  The scheduler must honor multiple resource requests
simultaneously as it seeks to allocate cores, GPUs, nodes, switches,
bandwidth, power, etc.

Here too, the system shall offer a plugin framework to support custom
algorithms for scheduling jobs to compute resources.  An essential
scheduling algorithm which must be included is backfill scheduling
(lower priority jobs are scheduled to run if they do not delay the
start of higher priority jobs).  In addition, qualities of service must
be implemented in the scheduler such that running jobs can be
preempted if needed to free up resources for more important jobs.
This involves not only selecting the best resources for a job, but
also identifying the set of jobs to preempt when such a policy is
enforced.

The output of a the job scheduling process is a schedule of which jobs
are mapped to which resources over a future, rolling period of time.
A by-product of this schedule is a projected start time for every
queued job that is included in the schedule.

% Don: The following three sections are not necessarily associated
% with the scheduler service and need to be moved to other parts of
% this doc.
%\textbf{Job Dispatching.} As time passes, the allocations described in
%the schedule must be created.  Running jobs that exceed their wall
%clock limit much be terminated and new jobs must be launched.
%Provisions must be made to launch multiple jobs simultaneously (or
%nearly simultaneously).

%\textbf{Job Status Reporting.} This is the facility for showing the
%user the status of their jobs and the job queue.  Job info must be
%available immediately after job submission, as it is pending, while it
%is running, and afterwards for a period to be determined.  The system
%should support multiple status requests at a time and reply with a
%second or two.  The system is designed to withstand denial of service
%attacks - whether deliberate or accidental.

%\textbf{Job and System Management.} This is the facility for manual
%intervention: boosting job priorities, modifying job characteristics,
%cancelling jobs, etc.  Modifying resource states does not have to be
%part of this facility.

\subsection{Resource Management API}

\paragraph{User Services}
This is the API for user or administrator interaction with the \ngrm.

\begin{itemize}
\item{$job\_submit()$: Submit a job allocation request and return a
  job ID}
\item{$job\_modify(JobID)$: Modify a job allocation request}
\item{$job\_status(JobID)$: Return complete information about a job}
\item{$job\_cancel(JobID)$: Cancel a job allocation request}
\item{$queue\_show()$: Return the current queue of jobs}
\item{$schedule\_show()$: Return the complete schedule as last
  calculated}
\end{itemize}

In addition, the following API provides users and administrators the
ability to query and modify the resource inventory, subject to roles
and permissions.

\begin{itemize}
\item{$resource\_add(Resource)$: Add a resource to the resource inventory}
\item{$resource\_modify(Resource)$: Modify the status/state of resource}
\item{$resource\_status(Resource)$: Return the status/state of resource}
\item{$resource\_remove(Resource)$: Remove a resource from the resource inventory}
\item{$resource\_group\_add(Resource)$: Add a resource group (e.g., node partition) to the resource inventory}
\item{$resource\_group\_status(Resource\_group)$: Return the status of a resource group}
\item{$resource\_group\_modify(Resource\_group)$: Modify the status/state of a resource group}
\item{$resource\_group\_remove(Resource)$: Remove a resource group from the resource inventory}
\end{itemize}

Similarly, the following API provides users and administrators the
ability to query and modify records in the user repository, subject to
roles and permissions.

\begin{itemize}
\item{$user\_add(User)$: Add a user with ACL to the user repository}
\item{$user\_modify(User)$: Modify the status or ACL of user}
\item{$user\_status(User)$: Return complete information about a user}
\item{$user\_remove(User)$: Remove a user from the user repository}
\end{itemize}

\paragraph{Scheduler Requests and Subscriptions}
This is the API the scheduler calls to request or subscribe to records
from the resource inventory, and job and user repositories.

\begin{itemize}
\item{$resource\_request()$: Request all schedulable resources from
  the resource inventory}
\item{$resource\_subscribe()$: Subscribe to changes to all schedulable
  resources from the resource inventory}
\item{$job\_request()$: Request all jobs from the job repository}
\item{$job\_subscribe()$: Subscribe to changes to all jobs from the
  job repository}
\item{$user\_request()$: Request all users from the user repository}
\item{$user\_subscribe()$: Subscribe to changes to all users from the
  user repository}
\end{itemize}

\paragraph{Scheduler Directives}
These are the WRAP service primitives the scheduler calls to initiate,
modify, and terminate WRAP instances. (Described in
Section~\ref{sect:prim} below)

\begin{itemize}
\item{$alloc()$}
\item{$realloc()$}
\item{$release()$}
\item{$launch()$}
\item{$destroy()$}
\end{itemize}

\ifwbs
%\newpage
\subsection{Resource Management WBS}

\begin{longtable}{|p{1cm}|p{10.2cm}|p{1cm}|p{1cm}|p{1.8cm}|}\hline
  \textbf{Item} & \textbf{Description}
                & \textbf{Deliv}\footnote{SD = software drop,
                        DR = design review, V = viewgraphs, D = document}
                & \textbf{Weeks} & \textbf{Depend} \\
  \hline
  \hline
  \multicolumn{5}{|l|}{2.1. \textbf{General Resource Management}} \\
  \hline
  2.1.1.& "Functional", high-level model for how the system above
         would work in \ngrm, including models for Resource Inventory,
          Job Data, Queues, Scheduling.
        & V
        & 
        & \\
  \hline
  \multicolumn{5}{|l|}{2.2. \textbf{Resource Database}} \\
  \hline
  2.2.1.& Resource and Job DB APIs (design and prototype).
        & DR
        & 
        & 2.1.1\\
  \hline
  2.2.2.& Resource Inventory (design and prototype)
        & DR
        & 
        & 2.1.1\\
  \hline
  2.2.3.& Job Repository (design and prototype)
        & DR
        & 
        & 2.1.1\\
  \hline
  2.2.4.& User Repository (design and prototype)
        & DR
        &
        & 2.1.1\\
  \hline
  2.2.5.& Comms integration
        & DR
        & 
        & 2.1.1.\\
  \hline
  2.2.6& Research existing work in resource description languages,
	  such as Condor's ClassAd language,
	  OAR's resource description language,
          Legion's object-oriented resource approach.
        & V
        & 
        & \\
  \hline
  2.2.7.& Design/Prototype resource description language.
        & DR
        & 
        & \\
  \hline
  \multicolumn{5}{|l|}{2.3. \textbf{Job Scheduler}} \\
  \hline
  2.3.1.& Scheduler (design and prototype)
        & DR
        & 
        & 2.1.1\\

  \hline
\end{longtable}
\fi
