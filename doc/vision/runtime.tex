\section{Workload Run-time and Placement} 
\label{sect:WRAP}

\ifcomments
\marginpar{\tiny {\bf kim-review:} WRAP section uses different
terminology than other sections.}
\fi
The Workload Run-time And Placement (WRAP) thrust area concerns all aspects of
executing transactions within a single job. 
While the scheduler sets the overall bound for both resources and time that a job 
can use, it does not dictate how to execute the various transactions of the job.
Thus, it is WRAP's responsibility to ensure that these transactions get executed 
most efficiently within this scheduler-set bound.
To embody \ngrm's new resource management paradigm, however, WRAP must provide the run-time
services beyond what the traditional paradigm requires. 
In addition to the traditional services such as bulk process launch and 
management, WRAP must provide advanced services to 
support conceptual models such as job hierarchy and resource elasticity 
described in Section~\ref{sect:models}.

\subsection{Lightweight Jobs and their Hierarchy}

\ifcomments
\marginpar{\tiny {\bf chris-review:}
Why do we need a hierarchy of LWJ's?  Are we reinventing
the same stuff we already built for jobs?  Can't we just do LWJ stuff
with jobs?}
As explained in Section~\ref{sect:comparison}, the traditional
approach models various transactions that a job executes simply as a set of
compute steps---e.g., {\tt job steps}.
As with other limitations of the traditional paradigm, this simple model
is ill-suited for designing our run-time services after it. 
Instead, WRAP requires a more powerful and flexible mechanism
to organize and group the processes that a job executes 
in accordance with their distinct functions or purposes. 
For example, all of the parallel processes of an MPI application may form a single 
compute function; all of the distributed processes of a parallel
debugger program may form a tool function that should be logically separate from 
the compute function; further, the compute function
may refine itself into several sub-functions to serve
independent power capping functions~\cite{RountreeRAPL} to different subsets of its processes.  

We use the notion of the lightweight job (LWJ) to realize the new model. 
An LWJ is a group of processes with a distinct function 
that has its own resource confinement that is a subset of 
the overall resources assigned to the job.
The most significant difference between the LWJ and the full job is that an LWJ
can share the compute resources with other LWJs of the same job. 
Further, the processes grouped by an LWJ can be refined into smaller LWJs,
and thus LWJs also form a hierarchy. Effectively, this bridges 
our general {\em job hierarchy model} into the fine-grained 
scope of ``within-job,'' following the same ``parent-child'' rules stated
in Section~\ref{sect:models}.

LWJs are the main means to provide group identifiers to WRAP services
so that WRAP can manage any meaningful set of processes as one coherent object. 
An LWJ may use a WRAP service to relate itself 
to another LWJ simply by passing the target LWJ's identifier.
This would be a common operation for tool LWJs as they often want to 
locate, synchronize with, and attach to MPI processes grouped through a compute LWJ.
Similarly, WRAP may move a portion of the compute resources (e.g., maximum power use) 
that one LWJ has been using to another LWJ. That forms our basis to enable 
our elasticity model at the within-job scope.


\begin{table}
\centering
\begin{tabular}{|l|l|}
\hline
Term & Description \\
\hline
$u$ & the containing job (universe) \\
$r_u$ & the overall resource bound the scheduler set for $u$ \\
$j$ & an LWJ in $u$ \\
$parent(j)$ & $j$'s parent in the LWJ hierarchy (parent of top-level LWJs is $u$) \\
$c_j$ & resource criteria for $j$ \\
$d_j$ & some data to be recorded by $j$ \\
$r_j$ & compute resources allocated to $j$ where $r_j \subseteq r_{parent(j)}$ \\
$cnew_j$ & criteria for additional resources for $j$ \\
$rnew_j$ & additional resources where $rnew_j \not\subseteq r_j$ and $rnew_j \subseteq r_{parent(j)}$ \\
$e_x$ & a run-time environment where $e_x \in E = \{e0, e1, ..., e_{m-1}\}$ \\
\hline
\end{tabular}
\caption{Definitions for Basic WRAP Service Parameters}
\label{tab:def}
\end{table}

\subsubsection{WRAP Service Primitives}
\label{sect:prim}

Table~\ref{tab:def} defines the basic elements relevant to WRAP run-time services.
For example, $j$ represents an LWJ in the hierarchy within the job, and 
$r_j$ denotes the compute resources to that this LWJ is confined.
Using these as our foundational parameters, WRAP now defines
the following service primitives to enable the new paradigm.

\begin{itemize}

\item{$alloc(j, c_j)$: allocates $r_j$ to $j$ from $r_{parent(j)}$ according to $c_j$.}

\item{$realloc(j, cnew_j)$: allocates $rnew_j$ from $r_{parent(j)}$ according to $cnew_j$ and updates $r_j$ such that $r_j = r_j \cup rnew_j$.}

\item{$release(j, subset(r_j))$: releases a subset of $r_j$ to $r_{parent(j)}$ and updates $r_j$ such that $r_j = r_j - subset(r_j)$.}

\item{$contain(j, e_x)$: contains $j$ in $e_x$.}

\item{$launch(j)$: spawns, maps and binds processes of $j$ on $r_j$ according to $c_j$. If this is an incremental launch, this spawns and binds only additional processes.}

\item{$destroy(j)$: kill processes of $j$ running on $r_j$. If this is a partial destroy, this kills only a subset of processes.}

\item{$bootstrap(j)$: bootstraps processes of $j$ across $r_j$ including dissemination of connection information. If this is a partial bootstrap--e.g., additional processes have been spawned or some processes have been killed, it only adjusts $j$ for the change}

\item{$split(j, marker)$: creates new child LWJs that includes all of the calling processes of $j$ with the same marker.}

\item{$record(j, d_j)$: records $j$'s attributes such as its $c_j$, fingerprint for $e_x$, and arbitrary information ($d_j$) about $j$.}

\item{$query(j)$: queries about $j$.}

\item{$sync(j_k, j_l)$: putting an LWJ, $j_k$, into a known state and providing another LWJ, $j_l$, with $j_k$'s identify info.}

\end{itemize}

\subsubsection{Higher-Level Services}
\label{sect:hiop}
Composing these primitives allow us to further build high-level services
such as the following. The primitives and high-level operations are our 
conceptual tools to test WRAP services to a myriad of requirements and use cases of \ngrm.

\begin{itemize}

\item{$init(j, c_j)$ = $<alloc(j, c_j), launch(j), bootstrap(j)>$}

\item{$cont\_init(j, c_j, e_x)$ = $< alloc(j, c_j), contain(j, e_x), launch(j), bootstrap(j) >$}

\item{$grow(j, cnew_j)$ = $<realloc(j, cnew_j), [launch(j), bootstrap(j)]>$,  
where $launch$ and $bootstrap$ are optional because they are only needed when $grow$ needs to launch additional processes. For instance, if $cnew_j$ is a power bound increase request, these operations are unnecessary.}

\item{$shrink(j,subset(r_j)$ = $<release(j, subset(r_j)), [destroy(j), bootstrap(j)]>$, 
where $destroy$ and $bootstrap$ are optional because they are only needed when $shrink$ needs to kill some processes of $j$.}

\item{$monitor(j, j_{mon}, c_j)$ = $<init(j, c_j), init(j_{mon}, c_j), sync(j, j_{mon})>$, where the first $init$ should be passed a special flag to cooperate with the subsequent $sync$ operation.}

\item{$log(j, j_{logger}, c_j)$ = $<init(j, c_j), init(j_{logger}, c_j), sync(j, j_{logger})>$, where the first $init$ should be passed a special flag to cooperate with the subsequent $sync$.}

\end{itemize}

%\subsection{Composed Use Cases}
%We now show the expressibility of the service primitives and
%high-level operations by mapping them to some of the
%use cases of the next generation resource management.
%
%\begin{itemize}
%
%\item{UC1: Use NGRM recursive execution to manage dedicated application test time.
%
%$<alloc(j, c_j), alloc(j_{t0}, c_{j_{t0}}), alloc(j_{t1}, c_{j_{t1}}), ...>$, where each $r_{j_i}$ represents distinct set of resources in $r_{j}$ and each $j_{ti}$ can further run a specific test under a different environment using services like $cont\_init$.}
%
%\item{UC3-UC5: Power utilization as a resource etc.
%
%We must combine our job model to the generic resource model to express these use cases.}
%
%\item{UC6: Live user feedback for job progress.
%
%$monitor(j, j_{progress\_monitor})$.}
%
%\item{UC7: Allow users to inject application specific data into data stream for jobs.
%
%$<initialize(j, c_j), record(j, d_j)>$.}
%
%\item{UC8: dsh|dshbak.
%
%I.e., $<init(j, c_j), init(j_{dsh}, c_j)>$}.
%
%\item{UC9: User control over system software levels.
%
%I.e., $<cont\_init(j, c_j, e_{prev.lvl}), record(j, d_j)>$.}
%
%\item{UC10: Testing system software releases.
%
%I.e., $<cont\_init(j, c_j,e_{toss.v}), record(j, d_j)>$.}
%
%\item{UC11: Integrated tool support.
%
%I.e., $<init(j, c_j), init(j_{STAT}, c_j), sync(j, j_{STAT})>$.}
%
%\item{UC12: Allocate spare resources from a common pool.
%
%I.e., $<init(j, c_j), grow(j_{scr}, cnew_j), sync(j, j_{scr})>$.}
%
%\item{UC12.1: Allocate additional power for some critial code region.
%
%I.e., $<init(j, c_j), grow(j, cnew_j), shrink(j)>$.}
%
%\item{UC13: Checkpoint/restart,
%
%I.e., $<init(j, c_j), init(j_{scr}, c_j), sync(j, j_{scr})>$.}
%
%\item{UC14: Ephemeral file system instances.
%
%We must combine our job model to the generic resource model to express these use cases.}
%
%\item{UC15: Integrated I/O forwarding support.
%
%$<alloc(j, c_j), init(j_{mpi}, c_{j_{mpi}}), init(j_{iof}, c_{iof}), sync(j_{mpi}, j_{iof})>$.}
%
%\item{UC16: Hadoop framework.
%
%$<init(j_{hadoop}, c_{j_{hadoop}})>$.}
%
%\item{UC17: User database instances.
%
%I.e., $<init(j_{mysql}, c_{j_{mysql}}), init(j_{atool}, c_{j_{atool}}), sync(j_{mysql}, c_{j_{atool}})>$.}
%
%\item{UC20: Provide "pre-job" resource information.
%
%$<alloc(j, c_j), query(j), init(j_{mpi}, c_{j_{mpi}})>$.}
%
%\item{UC19: Record HW configuration.
%
%$<init(j, c_j), record(j, d_j)>$.}
%
%\item{UC21: Virtual private networks for jobs.
%
%$<cont\_init(j, c_j, e_{vpn})>$.}
%
%\end{itemize}

\subsubsection{Elasticity Support}
The hierarchy of LWJs allows varying grain sizes of control 
for both process counts in sibling LWJs and 
resource distribution across these LWJs. This has many interesting
properties. For example, a compute LWJ can further refine itself 
into smaller LWJs representing subsets of processes with independent
resource confinement domains. 
As these smaller LWJs allocate, grow or shrink within the resource
limit of the parent LWJ, diverse set of resources including consumable ones
like power can be unevenly or evenly distributed across
these LWJs. In the case of power management, LWJs that are not in the critical path
in the parallel execution can reduce their power bound and return
the leftover power resources to its parent. The parent LWJ can then use the returned
resources in granting the {\em grow} requests that come from 
other LWJs that are in the critical path.    
This mechanism can support emerging power-aware computing 
that may want to cap power use differently and dynamically 
across different groups of MPI processes based on their execution patterns.  

\subsection{WRAP Software Architecture}
\label{sect:arch}
\begin{figure}
  \centering
    \includegraphics[width=3.0in]{WRAP_Base}
  \caption{Base WRAP Architecture}
  \label{fig:base}
\end{figure}
In this section, we will detail our WRAP software architecture 
and mechanisms that are needed to implement the proposed WRAP services.
We will first describe the base architecture that demonstrates
the basic WRAP capabilities of executing an LWJ on a set of compute
nodes, as our base resource type. 
Next, we will describe how we can extend this architecture
to enable other advanced services such abilities to synchronize 
two independent LWJs, to grow compute node resources allocated to an existing 
LWJ, and to handle other types of resources such as power.

\subsubsection{Base Architecture to Execute an LWJ}
Figure~\ref{fig:base} shows our base software architecture
that can provide a single LWJ ($j_k$) with WRAP service primitives:
$alloc()$,
$launch()$,
$bootstrap()$,
$contain()$,
$record()$, and
$query()$.
It assumes that the overlay network for $parent(j_k)$
already exists and that this existing network can support highly scalable,
resource-efficient communications for $j_k$ upon granting the $alloc(j_k)$ request. 
Our architecture requires that any overlay network instance recursively
supports communications of a child LWJ either
through an explicit instantiation of a separate overlay network
or through the existing overlay network. However, the latter model
requires to support a growth and/or reconfiguration
of the existing network to be elastic.\marginpar{\tiny Note that during the detailed 
design phase, WRAP and Comms Framework thrusts will co-design 
the actual communication mechanisms.}
WRAP then uses the overlay network for $j_k$ as well as
a key-value store to serve scalable process management
to $j_k$'s processes.
The following explains distributed key-value store mechanisms 
and key process management services in more detail.

\paragraph{Distributed Key-Value Store (DKVS)}
\label{sect:dkvs}
provides a scalable mechanism 
by which the processes of $j_k$ can
share arbitrary information in a key-value pair amongst them.
Conceptually, DKVS represents a global key-value tuple space
and any process of $j_k$ can store its data by associating them
with a unique key. To be memory-efficient,
however, DKVS must store the data in a distributed
manner. Thus, the overlay network of $j_k$ must be capable of hashing the key
to route its tuple to the home key-value store location. Global synchronization
mechanisms such as collective fence will be provided to force
memory consistency of DKVS across all processes.

Because our overlay network will have built-in routing
schemes to support requisite distribution schemes,
each home database itself can be a simple in-memory KVS.
It is for this reason that we we will first consider a readily available, simple
database implementation such as {\tt Redis}. 
Depending on our overlay network topology,
KVS can be fully distributed across all of the overlay network daemons.
An example topology to support the full distribution is a ``forest''
with $log(N)$ connections wherein any daemon can be
the root of a binomial tree.

Our DKVS will support a hierarchical tuple space for tighter
data encapsulation per LWJ, which can further lead to a higher level of 
protection.
More specifically, when an LWJ is
allocated, a new name scope for that LWJ will be
created in the DKVS, and information on the resource allocated
to that LWJ will be stored as part of the default $record$ service: e.g.,
$j_k$::resource $\rightarrow$ $<$ core\_count(1024), power\_bound(100kw), ... $>$.
This information is accessible by $j_k$ as well as
its immediate child LWJ $j_{k+1}$.
Similarly, when a daemon creates an MPI rank process, it will add the
personality of that process under this LWJ name scope
such as $j_k$::rank(128) $\rightarrow$ $<$ host IP, pid, executable path, ... $>$.
Finally, DKVS will allow any process of the LWJ to store arbitrary information
as part of $record(j_k, d_{j_k})$. All information stored
with $record$ will be pushed to $parent(j_k)$ when $j_k$
is destroyed. Thus, the information will ultimately find its place
in a persistent repository through the job hierarchy. In addition,
DKVS will further support $query$, providing the calling process
with underlying resource allocation information.

\paragraph{Scalable Process Management (ProcMan) Services}
\label{sect:procman}
can be implemented using the overlay network and DKVS as their 
basic scalable mechanisms. The scalable process management 
run-time services includes, but are not limited to, the following:

\begin{itemize}
\item{{\bf Bulk Process Creation and Stop}: The head daemon of the overlay network
receives a process creation request
through $launch(j_k)$ and propagates that command to the rest of the daemons
in $O(log(N))$. Upon receiving the request, each daemon forks and execs
local processes. If the request contains an optional {\tt sync\_assist} flag, the daemons
stop the processes immediately after the creation to support a subsequent $sync()$ issued
by another LWJ. In either case, the daemons store
information on the created target processes such as their process id, executable path
and hostname, into the DKVS.}

\item{{\bf Scalable Propagation of Environments}: The head daemon receives the environment
variables list and propagates that to the rest of the daemons
in $O(log(N))$. The daemons then concatenate this master environment variables
list to their local environment variables and export them to their
processes. If the head daemon receives an optional $contain$ request, that
request is also being propagated. The specified containing-environment is used to contain
the target processes.}

\item{{\bf Process Mapping, Binding and Confinement}: The daemons provide the newly created processes
with topology information to support their mapping, binding and confinement to the underlying 
resources. The daemons retrieve the topology information from the key-value store.}

\item{{\bf Scalable {\tt stderr/stdout} Handling}: The daemons receive
{\tt stderr} and {\tt stdout}
from their processes and scalably push and merge them through a tree in the overlay
network towards the head daemon. Output aggregation techniques
will include ways to reduce the output progressively at every merge step
in the tree either by applying a readily available
reduction filter or a user-provided one.}

\item{{\bf Scalable signal/{\tt stdin} Forwarding}: The head daemon receives a UNIX signal
or an input through {\tt stdin} and scalably propagates it to a specified set of daemons
through a tree in the overlay network in $O(log(N))$. Upon receiving the signal or {\tt stdin},
each daemon routes it to their corresponding processes.}

\item{{\bf Scalable Process Termination Detection and Analysis}: When one or more processes
in the LWJ are normally or abnormally terminated, their home daemons detect the event and notify
the head daemon through a tree in the overlay network. A time-out filter can be used at every step of
the tree network to merge the return codes and, if abnormal, the stack traces of 
the terminated processes. Upon receiving the aggregated
event, the head daemon will clean up the entire LWJ and also present
to the users concise information about the termination.}

\end{itemize}


\paragraph{A Unified Bootstrapping Mechanism }
\label{sect:bootstrap}
will be used to ease integration of various types of LWJs.
DKVS will be designed to support a wide range of existing bootstrap interfaces
for distributed software including PMI 1 and 2~\cite{PMI2}, PMGR Collective and COBO,
LaunchMON~\cite{launchmon} and LIBI~\cite{libi}. With support for these interfaces,
WRAP will be able to bootstrap various types of LWJs including a myriad of
MPI implementations, tools communication infrastructure such as MRNet
and also end-user tools such as STAT, TotalView and OpenSpeedShop.
Specifically, the PMI layers will be a very thin layer on top
of our DKVS implementation. We will support PMGR Collective,
COBO, LaunchMON, and LIBI such that each created process opens
up an ephemeral TCP port and store it as $j_k$::rank(128) $\rightarrow$ $<$ host IP, port $>$.
Then, each process in the binomial tree in these bootstrappers
will simply find the connection information of its parent as well as
its children using their ranks as the keys.

\subsubsection{Architectural Support for Synchronizing LWJs}
\label{sect:sync}
WRAP services must have an ability to relate an LWJ to another LWJ through $sync$.
For example, a tool may need to be co-located with an MPI program
and attached to its processes.
Thus, we must extend the base architecture to support this concept.
\begin{figure}
  \centering
    \includegraphics[width=3.0in]{WRAP_newJobFunction}
  \caption{Architectural support for ${sync(j_k, j_l)}$}
  \label{syncext}
\end{figure}
As shown in Figure~\ref{syncext}, when $alloc(j_l)$
is granted for a new additional LWJ ($j_l$),
the parent overlay network instantiates
another overlay network for $j_l$ and helps manage
the processes of $j_l$ in the same manner as the base case.
To support ${sync(j_k, j_l)}$,
however, a connection needs to be made between $j_l$'s
overlay and $j_k$'s overlay network.
For this purpose, we introduce the concept
of bridge. The bridge allows processes
of $j_l$ to be able to access DKVS of $j_k$, which includes
the mapping of the global MPI rank of a process of $j_k$
to its host name, pid, executable path~\cite{MPIRInterface},
information necessary for $j_l$ to locate all of $j_k$'s processes.
Alternatively, if the existing overlay network of $j_k$ is
capable of allocating and managing a new sibling LWJ
within itself, the need for a connection between two overlay
network and DKVS is eliminated.

\subsubsection{Architectural Support for Growing Compute Node Resources}
WRAP services must have an ability to grow the compute node resources that an LWJ ($j_k$)
uses by reallocating an additional set of compute nodes from the resources allocated
to $parent(j_k)$ and launching and bootstrapping additional processes
across them.
Figure~\ref{fig:ext2} shows the architectural support for this elasticity. 
\begin{figure}
  \centering
    \includegraphics[width=3.0in]{WRAP_grow}
  \caption{Architectural support for ${grow(j, cnew_j)}$}
  \label{fig:ext2}
\end{figure}
The scheme is essentially the same as that of $sync$.
Upon granting a reallocation of $rnew_j$,
$parent(j_k)$'s overlay network instantiates an overlay network
across $rnew_j$ and connects it to the existing overlay network
of $j_k$. The bridge support is again central for the connection.
Additional processes launched through the new network will
be able to access the DKVS associated with the existing $j_k$
name scope. Conversely, DKVS associated with these additional
processes will be made available to the existing $j_k$.
Alternatively, if the existing overlay network of $j_k$ is
capable of allocating and managing these additional processes
within itself, the need for a connection between two overlay
network and DKVS is eliminated. However, the existing overlay network
of $j_k$ must be capable of growing and
reconfiguring itself to join the additional compute nodes.

\subsubsection{Architectural Support for Power as a Resource Type}
As our {\em generalized resource model} will use the power bound as
a resource type, WRAP services must have an ability to allocate, grow
or shrink a power bound on an LWJ as well. 
As $j$ will get the power bound allocated to it, 
a power capping mechanism like RAPL~\cite{RountreeRAPL} can be used
to set the power bound of the allocated compute nodes.

The basic scheme computes the per-node power-bound average
and sets that average bound on each compute node.
For more advanced power-aware computing, subsets of processes will
be assigned to new ``power capping domain'' LWJs using $split()$.
The new power capping LWJs will independently issue $grow()$ and $shrink()$
operations on the power bound as the resource type.
This will allow the distribution of power bounds across the compute
nodes to vary while still providing the overall power bound guarantee.
These new LWJs will create new name scopes
in the DKVS under their parent name scope:
e.g., $j_k$::$j_{k+1}$::resource $\rightarrow$ $<$ size(128), power\_bound(12.5kW) $>$.

\subsection{Component-Wise Work Breakdown}
In this section, we summarize the requirements and work items for
the major components of the proposed WRAP system.\marginpar{\tiny Note that 
this sub-section is optional for reviewers to read, as it describes some
work breakdowns. But I'm leaving this sub-section so that 
reviewers may gain further insight into what need to be implemented 
to support the proposed WRAP architecture.}

\subsubsection{Overlay Network and Infrastructure Requirements}
The heart of WRAP lies in scalable and flexible overlay network support.
The overlay network's attributes that WRAP requires include:\marginpar{\tiny Note that the network requirements still need to be reconciled with section 5.4.} 

\begin{itemize}

\item{an ability to support our elasticity model
efficiently and scalably through expanding and shrinking
compute nodes and LWJ processes launched on them;}

\item{an ability for an arbitrary head daemon to broadcast
or multicast data to a set of other daemons through a binomial
or binary tree with $O(log(number\_of\_daemons))$;}

\item{an ability for an arbitrary head daemon to aggregate data
sent from a set of other daemons through the binomial
or binary tree with $O(log(number\_of\_daemons))$;}

\item{an ability to allow both preset and custom-made reduction
operators to reduce the aggregated data along the tree;}

\item{an ability to control data aggregation and reduction synchronously
with a mechanism to set an arbitrary time-out threshold: zero time-out means pass-through;
infinity time-out means global synchronization; and
in-between means partial synchronization with varying degrees;}

\item{an ability to route a key-value pair efficiently and
scalably by automatically hashing its key to find its home DKVS server
in support of get/put and global memory synchronization operations.}

\end{itemize}

\subsubsection{Process management}
To support scalable process management service described in Section~\ref{sect:procman},
the following components need to be investigated, designed and implemented:
\begin{itemize}
\item{an extensible communication protocol that allows
our process manager to conduct command and control
for all of its services;}
\item{a common data aggregation and reduction framework, techniques and API;}
\item{process management service components that
make use of the communication protocol and aggregation and reduction framework/API
and expose the services through high-level APIs;}
\item{executable commands such as an LWJ launcher that combines the
service components to implement certain types of process management
services for end users;}
\item{topology-aware process binding and mapping components as well as
communication mapping APIs that client software can use for efficient
mappings between its communication patterns and the topology.}
\end{itemize}

\subsubsection{DKVS}
DKVS requires the following components:
\begin{itemize}
\item{name scoping specification and API;}
\item{direct get/put methods on a readily-available key-value server;}
\item{remote get/put methods on distributed key-value servers by
integrating servers to the communication infrastructure;}
\item{synchronization mechanisms and APIs that guarantee memory consistency
across the distributed servers.}
\end{itemize}

\subsubsection{Bootstrap Interfaces}
The following components should be implemented and demonstrated
using DKVS support:
\begin{itemize}
\item{PMI2 and port a version of MPICH as a reference implementation;}
\item{PMGR Collective and/or COBO and port a version of MVAPICH as a reference implementation;}
\item{LIBI and port a version of LIBI-enabled MRNet as a reference implementation.}
\end{itemize}

\subsubsection{Job Function Synchronization}
\begin{itemize}
\item{{\tt MPIR\_proctable} gatherer that gathers {\tt MPIR\_proctable} spread throughout the
DKVS into a central location including the address space of the LWJ launcher;}
\item{MPIR debug interface~\cite{MPIRInterface} that makes use of DKVS and process
management services to support parallel debuggers;}
\item{co-locator that co-locates an additional LWJ's processes with
the target processes;}
\item{LaunchMON Back-end API that makes use of DKVS to allow another LWJ processes
to discover the locations of target processes scalably.}
\end{itemize}

\subsubsection{Power-Aware Computing}
\begin{itemize}
\item{{\em split()} that allows a compute LWJ to create smaller LWJs, and each serves as an independent power capping domain;}
\item{Dynamic power bound controller that manages expanding and shrinking of power bounds across these LWJs.}
\end{itemize}

\subsection{Phase-Based Work Breakdown}
To bring up the proposed WRAP system progressively and expediently, we use a phased approach.
WRAP requires four phases: the outcome of earlier phases becomes the fundamental 
building blocks for the later phases.\marginpar{\tiny Similarly to the previous sub-section, I'm leaving this sub-section to get some early feedback about our bring-up approach for WRAP.}


\subsubsection{Phase 1: Basic Building Blocks (BBB) design}

\begin{table}
\centering
\begin{tabular}{|l|l|l|l|}
\hline
Work Item & Description & Dependency & Deliverable \\
\hline
\multirow{2}{*}{Protocol design} & design/prototype procMan & \multirow{2}{*}{comm. co-design} & \multirow{2}{*}{paper and review} \\
& command/control comm. protocol & & \\ \hline
\multirow{2}{*}{Aggregation/reduction design} & design/prototype aggregation &  \multirow{2}{*}{comm. co-design} & \multirow{2}{*}{paper and review} \\
& reduction framework and APIs & & \\ \hline
\multirow{2}{*}{DKVS name scoping design} & design/prototype name scoping & \multirow{2}{*}{comm. co-design} & \multirow{2}{*}{paper and review} \\
& specification and APIs & & \\ \hline
\multirow{3}{*}{Key-value store investigation}& evaluate key-value store servers & \multirow{3}{*}{none} & \multirow{3}{*}{finding summary} \\
& via direct put/get methods using & & \\
& bootstrap and MPIR emulation& & \\ \hline
\multirow{2}{*}{Power controller investigation} & investigate Intel RAPL &  \multirow{2}{*}{RM design} & \multirow{2}{*}{paper and review} \\
& and ways to control power bound & & \\ \hline
\end{tabular}
\caption{Phase 1 BBB design milestones and deliverables}
\label{tab:phase1}
\end{table}

During this phase, we will design and prototype the basic building blocks required
by WRAP. This layer represents the lowest building blocks for the WRAP thrust and has fundamental
dependencies on the overlay network infrastructure design as shown in Table~\ref{tab:phase1}.
Thus, they must be co-designed.

\subsubsection{Phase 2: Service Building Blocks (SBB) design and BBB implementation}
\begin{table}
\centering
\begin{tabular}{|l|l|l|l|}
\hline
Work Item & Description & Dependency & Deliverable \\
\hline
\multirow{2}{*}{ProcMan design} & design/prototype process manager & \multirow{2}{*}{comm. infra} & \multirow{2}{*}{paper and review} \\
& package and APIs & & \\ \hline
\multirow{2}{*}{Topo-aware binding design} & design/prototype topo-aware binding & \multirow{2}{*}{RM design} & \multirow{2}{*}{paper and review} \\
& and mapping mechanisms and APIs & & \\ \hline
\multirow{3}{*}{Remote DKVS} & investigate DKVS via & \multirow{3}{*}{comm. infra} & \multirow{3}{*}{finding summary} \\
& remote put/get/sync using bootstrap & & \\
& and MPIR emulation & & \\ \hline
\multirow{5}{*}{BBB Implementation} & implement ProcMan comm. protocol & \multirow{5}{*}{BBB proto} & \multirow{5}{*}{software drop} \\
& aggregation/reduction framework and API & & \\
& DKVS name scoping API & & \\
& direct key-value store & & \\
& power controller & & \\ \hline
\end{tabular}
\caption{Phase 2 SBB design milestones and deliverables}
\label{tab:phase2}
\end{table}

During this phase, we will use the design and prototypes of basic building blocks
to design and prototype higher-level service layer called service building blocks (SBB)
packages. In addition, that effort will further validate the BBB design and prototypes
and hence we will lock in the BBB design and produce production-quality BBB implementations
during this phase.
As shown in Table~\ref{tab:phase2}, this phase is designed to provide core WRAP functionality
engine except for the actual user interfaces to expose.

\subsubsection{Phase 3: User Service Interfaces (USI) design and SBB implementation}
\begin{table}
\centering
\begin{tabular}{|l|l|l|l|}
\hline
Work Item & Description & Dependency & Deliverable \\
\hline
\multirow{2}{*}{LWJ utility design} & design/prototype LWJ utilities such & \multirow{2}{*}{SBB proto} & \multirow{2}{*}{paper and review} \\
& as LWJ launcher & & \\ \hline
\multirow{2}{*}{LWJ sync design} & design/prototype LWJ & \multirow{2}{*}{SBB proto} & \multirow{2}{*}{paper and review} \\
& synchronizers & & \\ \hline
\multirow{2}{*}{PMI2, PMGR, LIBI design} & design/prototype bootstrappers: & \multirow{2}{*}{SBB proto} & \multirow{2}{*}{finding summary} \\
& PMI2, PMGR/COBO and LIBI & & \\ \hline
\multirow{3}{*}{SBB implementation} & implement ProcMan package & \multirow{3}{*}{SBB proto} & \multirow{3}{*}{software drop} \\
& Topology-aware binding & & \\
& Remote DKVS & & \\ \hline
\end{tabular}
\caption{Phase 3 USI design milestones and deliverables}
\label{tab:phase3}
\end{table}

During this phase, we will use the design and prototype of service building blocks
to design and prototype the user-visible service layer called user service interfaces (USI).
In addition, once SBB prototypes are demonstrated that they are well-suited for the designed USI,
we will lock in the SBB design and produce production-quality SBB implementations.
As shown in Table~\ref{tab:phase3},
this phase will lay out the design of WRAP's external interfaces.

\subsubsection{Phase 4: USI implementation}
\begin{table}
\centering
\begin{tabular}{|l|l|l|l|}
\hline
Work Item & Description & Dependency & Deliverable \\
\hline
\multirow{2}{*}{LWJ utility implementation} & implement LWJ& \multirow{2}{*}{NGRM framework} & \multirow{2}{*}{software drop} \\
& utilities such as launcher & & \\ \hline
\multirow{2}{*}{LWJ sync implementation} & implement LWJ& \multirow{2}{*}{NGRM framework} & \multirow{2}{*}{software drop} \\
& LWJ synchronization & & \\ \hline
\multirow{2}{*}{PMI2, PMGR, LIBI design} & implement & \multirow{2}{*}{NGRM framework} & \multirow{2}{*}{software drop} \\
& PMI2, PMGR/COBO and LIBI & & \\ \hline
\end{tabular}
\caption{Phase 4 USI implementation}
\label{tab:phase4}
\end{table}

Once we demonstrate that USI prototypes sufficiently support both users and
other run-times via reference implementations, we lock in the SUI design and
produce production-quality USI implementations. Table~\ref{tab:phase4} shows
deliverables. The software drops will include the demonstration on client
software such as MPI, MRNet and other run-time tools.

\ifwbs
\newpage
\subsection{Workload Run-time WBS}

\begin{longtable}{|p{1cm}|p{10.2cm}|p{1cm}|p{1cm}|p{1.8cm}|}\hline
  \textbf{Item} & \textbf{Description}
                & \textbf{Deliv}\footnote{SD = software drop,
                        DR = design review, V = viewgraphs, D = document}
                & \textbf{Weeks} & \textbf{Depend} \\
  \hline
  \hline
  \multicolumn{5}{|l|}{4.1. \textbf{Runtime Basic Building Blocks}} \\
  \hline
  4.1.1.& Process manager command/control communication protocol design.
          (comms co-design)
        & DR, D
        & 
        & \\
  \hline
  \multicolumn{2}{|l|}{\em Note to Dong: agg/reduct framework moved to comms
              framework WBS}
        &
        &
        & \\
  \hline
  4.1.3.& Distributed key-value store name scoping specification and API.
          (comms co-design)
        & DR, D
        & 
        & \\
  \hline
  4.1.4.& Distributed key-value store investigation.  Evaluate servers
          via direct put/get methods using bootstrap and MPIR emulation.
        & V
        & 
        & \\
  \hline
  4.1.5.& Power control: Investigate  RAPL and ways to control power bound.
        & DR, D
        & 
        & RM \\
  \hline
  4.1.6.& Implement ProcMan communication protocol, DKVS name scoping API,
          direct key-value store, power controller.
        & SD
        & 
        & 4.1.1, 4.1.2, 4.1.3, 4.1.4, 4.1.5 \\
  \hline
  \multicolumn{5}{|l|}{4.2. \textbf{Runtime Service Building Blocks}} \\
  \hline
  4.2.1.& Process manager: design/prototype ProcMan and API.
        & DR, D
        & 
        & comms, 4.1.1\\
  \hline
  4.2.2.& Topo-aware binding: design/prototype binding and mapping
          mechanism and APIs.
        & DR, D
        & 
        & RM, 4.1.*\\
  \hline
  4.2.3.& Remote DKVS: investigate DKVS via remote put/get/sync using
	  bootstrap and MPIR emulation.
        & V
        & 
        & comms, 4.1.3(?), 4.1.4\\
  \hline
  4.2.4.& Implement ProcMan, topology-aware binding, remote DKVS.
        & SD 
        & 
        & 4.2.1, 4.2.2, 4.2.3 \\
  \hline
  \multicolumn{5}{|l|}{4.3. \textbf{Runtime User Service Interfaces}} \\
  \hline
  4.3.1.& Design/prototype job function utilities such as job function
          launcher.
        & DR, D
        & 
        & 4.2.1, 4.2.2, 4.2.3 \\
  \hline
  4.3.2.& Design/prototype job function synchronizers
        & DR, D
        & 
        & 4.2.1, 4.2.2, 4.2.3 \\
  \hline
  4.3.3.& Design/prototype bootstrappers: PMI2, PMGR/COBO, LIBI
        & V
        & 
        & 4.2.1, 4.2.2, 4.2.3 \\
  \hline
  4.3.4.& Implement job function utility.
        & SD
        & 
        & comms, 4.3.1 \\
  \hline
  4.3.5.& Implement job function sync.
        & SD
        & 
        & comms, 4.3.2 \\
  \hline
  4.3.6.& Implement PMI2, PMGR/COBO, LIBI
        & SD
        & 
        & comms, 4.3.3 \\
  \hline
\end{longtable}
\fi
